# ===========================================
# MCP Crawl4AI RAG - Dockerfile
# Version simplifiée et fiable
# ===========================================

FROM python:3.11-slim

# Définition des arguments de build
ARG PORT=8002

# Configuration de l'environnement
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH=/app \
    PYTHONHASHSEED=random \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    # Désactivation CUDA/GPU
    CUDA_VISIBLE_DEVICES=-1 \
    TORCH_USE_CUDA=0 \
    # Configuration de l'application
    PORT=${PORT} \
    HOST=0.0.0.0 \
    CRAWL4_AI_BASE_DIRECTORY=/app/data \
    TRANSFORMERS_CACHE=/app/.cache/huggingface \
    TOKENIZERS_PARALLELISM=false \
    LOG_LEVEL=info

# Installation des dépendances système
RUN apt-get update && apt-get install -y \
    curl \
    python3-dev \
    libxml2-dev \
    libxslt1-dev \
    zlib1g-dev \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Création des répertoires nécessaires
RUN mkdir -p /app/data /app/logs /app/.cache/huggingface /app/src
WORKDIR /app

# Installation des outils de base
RUN pip install --no-cache-dir --upgrade pip setuptools wheel

# Copie du fichier de dépendances
COPY pyproject.toml ./

# Installation des dépendances principales
RUN pip install --no-cache-dir -e .

# Installation des dépendances une par une pour éviter les problèmes de syntaxe
RUN pip install --no-cache-dir torch==2.0.1+cpu --index-url https://download.pytorch.org/whl/cpu
RUN pip install --no-cache-dir "sentence-transformers>=2.2.2,<2.3.0"
RUN pip install --no-cache-dir "crawl4ai>=0.6.0,<0.7.0"
RUN pip install --no-cache-dir "fastmcp>=2.9.0,<3.0.0"
RUN pip install --no-cache-dir "supabase>=2.0.0,<3.0.0"
RUN pip install --no-cache-dir "uvicorn[standard]==0.22.0"
RUN pip install --no-cache-dir "fastapi==0.100.0"
RUN pip install --no-cache-dir "transformers==4.30.0"
RUN pip install --no-cache-dir "psycopg2-binary==2.9.0"
RUN pip install --no-cache-dir "qdrant-client>=1.7.0,<2.0.0"
RUN pip install --no-cache-dir "pydantic==2.0.0"
RUN pip install --no-cache-dir "python-dotenv==1.0.0"
RUN pip install --no-cache-dir "loguru==0.7.0"
RUN pip install --no-cache-dir "neo4j==5.0.0"
RUN pip install --no-cache-dir "beautifulsoup4==4.12.0"
RUN pip install --no-cache-dir "lxml==4.9.0"
RUN pip install --no-cache-dir "accelerate==0.20.0"
RUN pip install --no-cache-dir "numpy==1.24.0"
RUN pip install --no-cache-dir "httpx==0.24.0"

# Copie du code source
COPY . .

# Création du répertoire pour les modèles
RUN mkdir -p /app/models

# Téléchargement des modèles nécessaires
RUN python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2', cache_folder='/app/models')"

# Configuration des permissions
RUN groupadd -r appuser && useradd -r -g appuser appuser \
    && chown -R appuser:appuser /app \
    && chmod -R 755 /app \
    && chmod +x /app/start-mcp-service.sh

# Configuration du conteneur
USER appuser
WORKDIR /app/src
EXPOSE ${PORT}

# Vérification de l'installation des dépendances
RUN python -c "import uvicorn, fastapi, sentence_transformers, torch; print(f'Versions: uvicorn={uvicorn.__version__}, fastapi={fastapi.__version__}, sentence_transformers={sentence_transformers.__version__}, torch={torch.__version__}, CUDA available={torch.cuda.is_available()}')"

# Commande de démarrage
CMD ["/app/start-mcp-service.sh"]
